<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8" />
  <title>MediaPipe Hands - Gesture Demo</title>
  <style>
    body { font-family: sans-serif; text-align: center; }
    video, canvas { width: 100%; max-width: 400px; }
    #status { font-size: 18px; margin: 10px; color: blue; }
    #action { font-size: 24px; font-weight: bold; margin: 10px; color: red; }
  </style>
</head>

<body>
  <h2>MediaPipe Hands - Hand Tracking</h2>
  <div id="status">模型加载中，请稍等...</div>
  <div id="action">等待动作...</div>
  <video id="video" autoplay playsinline></video>
  <canvas id="canvas"></canvas>

  <script type="module">
    import { HandLandmarker, FilesetResolver, DrawingUtils } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const statusEl = document.getElementById("status");
    const actionEl = document.getElementById("action");

    let handLandmarker;
    let lastX = null;
    let lastY = null;

    async function init() {
      statusEl.textContent = "正在加载模型...";
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
      );

      handLandmarker = await HandLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm/hand_landmarker.task",
        },
        runningMode: "VIDEO",
        numHands: 1,
      });

      statusEl.textContent = "模型加载完成，等待手势...";
      startCamera();
    }

    function startCamera() {
      navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
        video.srcObject = stream;
        video.onloadedmetadata = () => {
          video.play();
          requestAnimationFrame(loop);
        };
      }).catch(err => {
        statusEl.textContent = "无法访问摄像头，请允许权限。";
        console.error(err);
      });
    }

    async function loop(timestamp) {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      const results = await handLandmarker.detectForVideo(video, timestamp);
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      if (results.landmarks && results.landmarks.length > 0) {
        const drawingUtils = new DrawingUtils(ctx);
        for (const landmarks of results.landmarks) {
          drawingUtils.drawConnectors(landmarks, HandLandmarker.HAND_CONNECTIONS);
          drawingUtils.drawLandmarks(landmarks);
        }

        // 动作识别（用手腕关键点）
        const wrist = results.landmarks[0][0]; // 手腕
        let action = "等待动作...";

        if (lastX !== null && lastY !== null) {
          const dx = wrist.x - lastX;
          const dy = wrist.y - lastY;

          if (Math.abs(dx) > Math.abs(dy)) {
            if (dx > 0.02) action = "RIGHT";
            else if (dx < -0.02) action = "LEFT";
          } else {
            if (dy > 0.02) action = "DOWN";
            else if (dy < -0.02) action = "UP";
          }
        }

        lastX = wrist.x;
        lastY = wrist.y;
        actionEl.textContent = action;
      } else {
        actionEl.textContent = "没有检测到手";
      }

      requestAnimationFrame(loop);
    }

    init();
  </script>
</body>
</html>
